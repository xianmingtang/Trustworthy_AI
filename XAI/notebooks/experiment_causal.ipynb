{
 "cells": [
  {
   "cell_type": "code",
   "id": "4a967d92-cb58-4da9-8693-d4b0053577d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T23:02:33.223053Z",
     "start_time": "2025-09-14T23:02:33.219884Z"
    }
   },
   "source": [
    "from gmpy2.gmpy2 import random_state\n",
    "\n",
    "# Quick Start: Causal Analysis\n",
    "'''\n",
    "This notebook demonstrates:\n",
    "1. Load & clean data\n",
    "2. Feature selection (IAMB)\n",
    "3. Causal discovery (PC)\n",
    "4. Effect estimation (ATE)\n",
    "5. Visualization (DAG)\n",
    "'''"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis notebook demonstrates:\\n1. Load & clean data\\n2. Feature selection (IAMB)\\n3. Causal discovery (PC)\\n4. Effect estimation (ATE)\\n5. Visualization (DAG)\\n'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 131
  },
  {
   "cell_type": "code",
   "id": "61dc89c6-aae4-4227-b7b7-e220b8e2f3db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T23:02:33.232993Z",
     "start_time": "2025-09-14T23:02:33.230642Z"
    }
   },
   "source": [
    "import sys, os\n",
    "\n",
    "# 1. Compute project root: one level up from the notebook folder\n",
    "proj_root = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "\n",
    "# 2. Prepend it to sys.path\n",
    "if proj_root not in sys.path:\n",
    "    sys.path.insert(0, proj_root)"
   ],
   "outputs": [],
   "execution_count": 132
  },
  {
   "cell_type": "code",
   "id": "2cd317df-c995-45d8-b948-c135499060dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T23:02:33.242454Z",
     "start_time": "2025-09-14T23:02:33.239331Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from causallearn.utils.cit import kci\n",
    "from causal import preprocess\n",
    "from causal import restriction\n",
    "from causal import causal_discovery as cd\n",
    "from causal import identifier as ide\n",
    "from causal import visualization as vis\n",
    "from causal import utils\n",
    "from causal import refuter as ref\n",
    "from causallearn.search.FCMBased.lingam.utils import make_dot\n",
    "from causallearn.search.FCMBased import lingam\n",
    "from dowhy import CausalModel\n",
    "from causallearn.utils.GraphUtils import GraphUtils\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ],
   "outputs": [],
   "execution_count": 133
  },
  {
   "cell_type": "code",
   "id": "4e07adb55ff73b06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T23:02:34.051133Z",
     "start_time": "2025-09-14T23:02:33.247377Z"
    }
   },
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    '''\n",
    "    1. Data Loading and Preprocessing\n",
    "    '''\n",
    "\n",
    "    path = '../Dataset/veremi_extension_simple.csv'\n",
    "    data_origin = pd.read_csv(path)\n",
    "    print(f'total:{data_origin.shape}')\n",
    "    # print(data_origin)\n",
    "\n",
    "    # filter Ddos and normal data\n",
    "    data_origin = data_origin[data_origin['class'].isin([0, 11, 12, 13, 16, 17])]\n",
    "\n",
    "    # filter fake data attack and normal data\n",
    "    # data_origin = data_origin[data_origin['class'].isin([0, 1, 2, 3, 4, 5, 6, 7, 8])]\n",
    "\n",
    "    # filter sybil attack and normal data\n",
    "    # data_origin = data_origin[data_origin['class'].isin([0, 14, 15, 16, 17])]\n",
    "    # print(data_origin.head(5))\n",
    "\n",
    "    # filter sybil disruptive/data reply and normal data\n",
    "    # data_origin = data_origin[data_origin['class'].isin([0, 10])]\n",
    "    # print(data_origin.head(5))\n",
    "\n",
    "    data_origin = utils.collapse_classes(data_origin, 1)\n",
    "    print(data_origin[data_origin['class'] == 1].shape)\n",
    "\n",
    "    data_origin = utils.min_sample_retention(data_origin, test_size = 100000, random_state=42)\n",
    "    # print(data_origin)\n",
    "\n",
    "    print(data_origin[data_origin['class'] == 1].shape)\n",
    "    print('*-' * 50)\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:(1048575, 20)\n",
      "(143130, 20)\n",
      "(18668, 20)\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n"
     ]
    }
   ],
   "execution_count": 134
  },
  {
   "cell_type": "code",
   "id": "26282760-6acc-4a30-93fd-89ed30a4d5fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T23:02:34.122380Z",
     "start_time": "2025-09-14T23:02:34.054699Z"
    }
   },
   "source": [
    "# Data Cleaning:\n",
    "drop_column = ['type','Attack','Attack_type']\n",
    "data_processed = preprocess.clean(data_origin, drop_column=drop_column, drop_na=True, data_numerical=True)\n",
    "\n",
    "# Standardize features, target keep same as original data_processed:\n",
    "data_processed = preprocess.standardize(data_processed, ['class','sendTime','sender','senderPseudo','messageID'])\n",
    "\n",
    "# Combine axis related data such as pos, spd etc. by using M = \\sqrt{X^2 + Y^2 + Z^2}\n",
    "data_processed = preprocess.add_vector_magnitude_column(data_processed, ['posx', 'posy', 'posz'], 'pos')\n",
    "data_processed = preprocess.add_vector_magnitude_column(data_processed, ['spdx', 'spdy', 'spdz'], 'spd')\n",
    "data_processed = preprocess.add_vector_magnitude_column(data_processed, ['aclx', 'acly', 'aclz'], 'acl')\n",
    "data_processed = preprocess.add_vector_magnitude_column(data_processed, ['hedx', 'hedy', 'hedz'], 'hed')\n",
    "data_processed.drop(\n",
    "    columns=['posx', 'posy', 'posz', 'spdx', 'spdy', 'spdz', 'aclx', 'acly', 'aclz', 'hedx', 'hedy', 'hedz','sender'],\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "# ID mapping to 0-N\n",
    "# data_processed['senderPseudo'] = data_processed['senderPseudo'].astype('category').cat.codes\n",
    "# data_processed['messageID'] = data_processed['messageID'].astype('category').cat.codes\n",
    "\n",
    "# …run two separate CausalModel objects with *_z columns as treatment\n",
    "\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    print(data_processed)\n",
    "    print(type(data_processed))\n",
    "print('*-' * 50)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           sendTime  senderPseudo  messageID  class       pos       spd  \\\n",
      "28678   72524.93554     101314037  427449123      0  1.177110  1.905615   \n",
      "200107  25997.45431      10126152   24069906      1  2.795565  0.062502   \n",
      "430083  51456.19907      10747875  227970587      0  0.889361  1.033074   \n",
      "672050  63495.90880      10977316  294191998      1  1.685966  1.864182   \n",
      "598240  62513.11618      10942036  281163403      0  1.820064  2.141214   \n",
      "...             ...           ...        ...    ...       ...       ...   \n",
      "867493  57363.97413      10824615  246269618      0  1.185938  1.932187   \n",
      "611642  62679.81393      10948636  282448261      0  1.032245  1.947845   \n",
      "255116  26914.40500      10152432   32398993      0  1.403602  0.342722   \n",
      "907233  40395.11123      20524134  159076506      1  1.373236  0.062503   \n",
      "807673  54925.09253      10797675  240617007      0  1.541126  1.599667   \n",
      "\n",
      "             acl       hed  \n",
      "28678   0.053295  1.402316  \n",
      "200107  0.005667  0.124483  \n",
      "430083  1.867734  1.300563  \n",
      "672050  0.313507  1.374822  \n",
      "598240  0.343610  1.558776  \n",
      "...          ...       ...  \n",
      "867493  0.352998  1.503008  \n",
      "611642  0.062069  1.389474  \n",
      "255116  1.299022  1.446657  \n",
      "907233  0.005626  1.325739  \n",
      "807673  0.088822  1.358574  \n",
      "\n",
      "[100000 rows x 8 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n"
     ]
    }
   ],
   "execution_count": 135
  },
  {
   "cell_type": "code",
   "id": "e7777558-ca2a-4c1d-9159-b3fff7f48662",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T23:02:34.148353Z",
     "start_time": "2025-09-14T23:02:34.132521Z"
    }
   },
   "source": [
    "# X = data_processed.iloc[:, 1:].copy()     # 8 features\n",
    "# y = data_processed.iloc[:, 0].copy()\n",
    "#\n",
    "y = data_processed['class'].copy()\n",
    "X = data_processed.drop(columns='class')\n",
    "\n",
    "# print(X)\n",
    "# print('*-' * 50)\n",
    "# print(y)\n",
    "# print('*-' * 50)\n",
    "\n",
    "df = pd.concat([X, y.rename('class')], axis=1)\n",
    "print(df)\n",
    "node_names = df.columns.tolist()\n",
    "print(node_names)\n",
    "\n",
    "zeros = df.columns[df.var()==0]\n",
    "print(\"zero var column：\", zeros.tolist())\n",
    "\n",
    "corr = df.corr().abs()\n",
    "perfect_pairs = [(i,j) for i in corr.columns for j in corr.columns\n",
    "                 if i!=j and corr.loc[i,j]==1.0]\n",
    "print(\"corr column：\", perfect_pairs)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           sendTime  senderPseudo  messageID       pos       spd       acl  \\\n",
      "28678   72524.93554     101314037  427449123  1.177110  1.905615  0.053295   \n",
      "200107  25997.45431      10126152   24069906  2.795565  0.062502  0.005667   \n",
      "430083  51456.19907      10747875  227970587  0.889361  1.033074  1.867734   \n",
      "672050  63495.90880      10977316  294191998  1.685966  1.864182  0.313507   \n",
      "598240  62513.11618      10942036  281163403  1.820064  2.141214  0.343610   \n",
      "...             ...           ...        ...       ...       ...       ...   \n",
      "867493  57363.97413      10824615  246269618  1.185938  1.932187  0.352998   \n",
      "611642  62679.81393      10948636  282448261  1.032245  1.947845  0.062069   \n",
      "255116  26914.40500      10152432   32398993  1.403602  0.342722  1.299022   \n",
      "907233  40395.11123      20524134  159076506  1.373236  0.062503  0.005626   \n",
      "807673  54925.09253      10797675  240617007  1.541126  1.599667  0.088822   \n",
      "\n",
      "             hed  class  \n",
      "28678   1.402316      0  \n",
      "200107  0.124483      1  \n",
      "430083  1.300563      0  \n",
      "672050  1.374822      1  \n",
      "598240  1.558776      0  \n",
      "...          ...    ...  \n",
      "867493  1.503008      0  \n",
      "611642  1.389474      0  \n",
      "255116  1.446657      0  \n",
      "907233  1.325739      1  \n",
      "807673  1.358574      0  \n",
      "\n",
      "[100000 rows x 8 columns]\n",
      "['sendTime', 'senderPseudo', 'messageID', 'pos', 'spd', 'acl', 'hed', 'class']\n",
      "zero var column： []\n",
      "corr column： []\n"
     ]
    }
   ],
   "execution_count": 136
  },
  {
   "cell_type": "code",
   "id": "3556240f-2b0d-40e1-b434-1dc5d038ca4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T23:02:34.154654Z",
     "start_time": "2025-09-14T23:02:34.152495Z"
    }
   },
   "source": [
    "'''\n",
    "2.  Background knowledge creation\n",
    "'''\n",
    "bk_pc = restriction.PC_BGKnowledge(df, X, 'class')\n",
    "bk_DirectLiNGAM = restriction.DirectLiNGAM_BGKnowledge(node_names, 'class')\n",
    "# print(bk_DirectLiNGAM)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'causallearn.utils.PCUtils.BackgroundKnowledge.BackgroundKnowledge'>\n"
     ]
    }
   ],
   "execution_count": 137
  },
  {
   "cell_type": "code",
   "id": "2a6c99e9-d803-4159-aa54-5bfc3ff714db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T23:02:34.397867Z",
     "start_time": "2025-09-14T23:02:34.162563Z"
    }
   },
   "source": [
    "'''\n",
    "3.  Algorithm for causal discovery\n",
    "'''\n",
    "\n",
    "'''3.1 Constrained Based'''\n",
    "# PC algorithm with Kernal-based independence test\n",
    "cg_pc = cd.pc_algorithm(\n",
    "    df,\n",
    "    indep_test_func = kci,\n",
    "    alpha = 0.01,\n",
    "    uc_rule = 1,\n",
    "    max_k = 2,\n",
    "    background_knowledge = bk_pc,\n",
    "    node_names = node_names\n",
    ")\n",
    "\n",
    "pdy_PC = GraphUtils.to_pydot(cg_pc.G)\n",
    "print(type(pdy_PC))\n",
    "print(pdy_PC)\n",
    "pdy_PC.write_png('PC.png')\n",
    "\n",
    "adj_matrix_PC = utils.dot_to_adj(pdy_PC, desired_order = node_names)\n",
    "print(adj_matrix_PC)\n",
    "print(type(adj_matrix_PC))\n",
    "\n",
    "# FCI algorithm with Kernal-based independence test\n",
    "# cg_fci, edges = cd.fci_algorithm(\n",
    "#     df,\n",
    "#     indep_test_func=kci,\n",
    "#     alpha=0.01,\n",
    "#     depth=-1,\n",
    "#     max_path_length=-1,\n",
    "#     verbose=False,\n",
    "#     show_progress=True,\n",
    "#     background_knowledge = bk_pc,\n",
    "#     node_names = node_names\n",
    "# )\n",
    "# pdy = GraphUtils.to_pydot(cg_fci)\n",
    "# pdy.write_png('FCI.png')"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a60c2953cb8d485881ce327bd8e9709b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pydot.core.Dot'>\n",
      "digraph {\n",
      "fontsize=18;\n",
      "dpi=200;\n",
      "0 [label=sendTime];\n",
      "0 [label=sendTime];\n",
      "1 [label=senderPseudo];\n",
      "1 [label=senderPseudo];\n",
      "2 [label=messageID];\n",
      "2 [label=messageID];\n",
      "3 [label=pos];\n",
      "3 [label=pos];\n",
      "4 [label=spd];\n",
      "4 [label=spd];\n",
      "5 [label=acl];\n",
      "5 [label=acl];\n",
      "6 [label=hed];\n",
      "6 [label=hed];\n",
      "7 [label=class];\n",
      "7 [label=class];\n",
      "1 -> 0 [dir=both, arrowtail=none, arrowhead=normal];\n",
      "0 -> 2 [dir=both, arrowtail=none, arrowhead=none];\n",
      "3 -> 0 [dir=both, arrowtail=none, arrowhead=normal];\n",
      "4 -> 0 [dir=both, arrowtail=none, arrowhead=normal];\n",
      "1 -> 2 [dir=both, arrowtail=none, arrowhead=normal];\n",
      "1 -> 3 [dir=both, arrowtail=none, arrowhead=normal];\n",
      "1 -> 7 [dir=both, arrowtail=none, arrowhead=normal];\n",
      "3 -> 2 [dir=both, arrowtail=none, arrowhead=normal];\n",
      "4 -> 2 [dir=both, arrowtail=none, arrowhead=normal];\n",
      "5 -> 3 [dir=both, arrowtail=none, arrowhead=normal];\n",
      "6 -> 3 [dir=both, arrowtail=none, arrowhead=normal];\n",
      "3 -> 7 [dir=both, arrowtail=none, arrowhead=normal];\n",
      "4 -> 5 [dir=both, arrowtail=none, arrowhead=none];\n",
      "4 -> 6 [dir=both, arrowtail=none, arrowhead=none];\n",
      "4 -> 7 [dir=both, arrowtail=none, arrowhead=normal];\n",
      "5 -> 6 [dir=both, arrowtail=none, arrowhead=none];\n",
      "6 -> 7 [dir=both, arrowtail=none, arrowhead=normal];\n",
      "}\n",
      "\n",
      "[[0. 1. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 1. 1. 0. 1. 0.]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "execution_count": 138
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T23:02:34.406505Z",
     "start_time": "2025-09-14T23:02:34.403541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''3.2 constrained functional'''\n",
    "# LiNGAM\n",
    "# model_LiNGAM = lingam.ICALiNGAM(random_state=42)\n",
    "# model_LiNGAM.fit(df)\n",
    "# print(model_LiNGAM.adjacency_matrix_)\n",
    "# print(type(model_LiNGAM.adjacency_matrix_))\n",
    "# graph_dot_model_LiNGAM = make_dot(model_LiNGAM.adjacency_matrix_, labels=node_names)\n",
    "# graph_dot_model_LiNGAM.format = 'png'\n",
    "# output_path = graph_dot_model_LiNGAM.render(filename='LiNGAM',directory='.',cleanup=True)\n",
    "#\n",
    "#\n",
    "# # Direct-LiNGAM\n",
    "# model_DirectLiNGAM = lingam.DirectLiNGAM(\n",
    "#     random_state=42,\n",
    "#     prior_knowledge=None,\n",
    "#     apply_prior_knowledge_softly=False,\n",
    "#     measure='pwling',\n",
    "# )\n",
    "#\n",
    "# model_DirectLiNGAM.fit(df)\n",
    "# graph_dot_DirectLiNGAM = make_dot(model_DirectLiNGAM.adjacency_matrix_, labels=node_names)\n",
    "# graph_dot_DirectLiNGAM.format = 'png'\n",
    "# output_path = graph_dot_DirectLiNGAM.render(filename='DirectLiNGAM',directory='.',cleanup=True)"
   ],
   "id": "b2a8449ef880fd74",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.2 constrained functional'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 139
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T23:02:34.617954Z",
     "start_time": "2025-09-14T23:02:34.418359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''3.4 Boss'''\n",
    "\n",
    "G = cd.boss(\n",
    "    df.to_numpy(),\n",
    "    score_func='local_score_BIC',\n",
    "    node_names=node_names\n",
    ")\n",
    "\n",
    "pdy_BOSS = GraphUtils.to_pydot(G)\n",
    "print(type(pdy_BOSS))\n",
    "pdy_BOSS.write_png(\"BOSS.png\")\n",
    "\n",
    "adj_matrix_BOSS = utils.dot_to_adj(pdy_BOSS, desired_order = node_names)\n",
    "print(adj_matrix_BOSS)\n",
    "print(type(adj_matrix_BOSS))\n"
   ],
   "id": "fbc4b5f1adb4f594",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order:[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "leaf_idx:7\n",
      "gsts:[<causallearn.search.PermutationBased.gst.GST object at 0x35eb14970>, <causallearn.search.PermutationBased.gst.GST object at 0x35eb14790>, <causallearn.search.PermutationBased.gst.GST object at 0x35eb14f70>, <causallearn.search.PermutationBased.gst.GST object at 0x35eb144f0>, <causallearn.search.PermutationBased.gst.GST object at 0x35eb14d90>, <causallearn.search.PermutationBased.gst.GST object at 0x35eb15090>, <causallearn.search.PermutationBased.gst.GST object at 0x35eb157b0>, <causallearn.search.PermutationBased.gst.GST object at 0x35eb16b90>]\n",
      "=== GST #0 ===\n",
      "vertex        : 0\n",
      "forbidden     : [0, 7]\n",
      "required      : []\n",
      "root.grow_score : -1947164.500571181\n",
      "root.shrink_score: -1947164.500571181\n",
      "=== GST #1 ===\n",
      "vertex        : 1\n",
      "forbidden     : [1, 7]\n",
      "required      : []\n",
      "root.grow_score : -3755885.846594797\n",
      "root.shrink_score: -3755885.846594797\n",
      "=== GST #2 ===\n",
      "vertex        : 2\n",
      "forbidden     : [2, 7]\n",
      "required      : []\n",
      "root.grow_score : -3736491.160813776\n",
      "root.shrink_score: -3736491.160813776\n",
      "=== GST #3 ===\n",
      "vertex        : 3\n",
      "forbidden     : [3, 7]\n",
      "required      : []\n",
      "root.grow_score : 117452.13115848572\n",
      "root.shrink_score: 117452.13115848572\n",
      "=== GST #4 ===\n",
      "vertex        : 4\n",
      "forbidden     : [4, 7]\n",
      "required      : []\n",
      "root.grow_score : 64817.018375916225\n",
      "root.shrink_score: 64817.018375916225\n",
      "=== GST #5 ===\n",
      "vertex        : 5\n",
      "forbidden     : [5, 7]\n",
      "required      : []\n",
      "root.grow_score : -5395.553886817175\n",
      "root.shrink_score: -5395.553886817175\n",
      "=== GST #6 ===\n",
      "vertex        : 6\n",
      "forbidden     : [6, 7]\n",
      "required      : []\n",
      "root.grow_score : 374386.28699935303\n",
      "root.shrink_score: 374386.28699935303\n",
      "=== GST #7 ===\n",
      "vertex        : 7\n",
      "forbidden     : [7]\n",
      "required      : []\n",
      "root.grow_score : 188498.00007905148\n",
      "root.shrink_score: 188498.00007905148\n",
      "parents:{0: [], 1: [], 2: [], 3: [], 4: [], 5: [], 6: [], 7: []}\n",
      "[3, 2, 1, 7, 5, 4, 0, 6]\n",
      "BOSS edge count: 18    [5, 4, 0, 6, 2, 7, 3, 1]\n",
      "BOSS edge count: 18    \n",
      "BOSS completed in: 0.01s \n",
      "<class 'pydot.core.Dot'>\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 1. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 0.]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alextang/Documents/Dev/Py_Projects/XAI/causal/causal_discovery.py:276: UserWarning: Using 'local_score_BIC_from_cov' instead for efficiency\n",
      "  warnings.warn(\"Using 'local_score_BIC_from_cov' instead for efficiency\")\n"
     ]
    }
   ],
   "execution_count": 140
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T23:20:52.504087Z",
     "start_time": "2025-09-14T23:02:34.626633Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''3.5 NOTEARS'''\n",
    "\n",
    "# X = df.values.astype(float)\n",
    "# X = (X - X.mean(0, keepdims=True)) / (X.std(0, keepdims=True) + 1e-8)\n",
    "# print(X)\n",
    "\n",
    "adj_matrix_NOTEARS = cd.notears_linear(\n",
    "    df.values,\n",
    "    lambda1= 0.5,\n",
    "    loss_type='logistic'\n",
    ") #penalty_factor=2.0, discourage_parents=7\n",
    "\n",
    "print(adj_matrix_NOTEARS)\n",
    "print(type(adj_matrix_NOTEARS))\n",
    "\n",
    "# NOTEARS_adjacency_matrix = pd.DataFrame(w, index=node_names, columns=node_names)\n",
    "# print(NOTEARS_adjacency_matrix)\n",
    "# print(type(NOTEARS_adjacency_matrix))\n",
    "#\n",
    "graph_dot_NOTEARS = make_dot(adj_matrix_NOTEARS, labels=node_names)\n",
    "graph_dot_NOTEARS.format = 'png'\n",
    "output_path = graph_dot_NOTEARS.render(filename='NOTEARS',directory='.',cleanup=True)"
   ],
   "id": "44b3d406aff0377e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alextang/Documents/Dev/Py_Projects/.conda_env/lib/python3.10/site-packages/scipy/linalg/_matfuncs.py:373: RuntimeWarning: overflow encountered in matmul\n",
      "  eAw = eAw @ eAw\n",
      "/Users/alextang/Documents/Dev/Py_Projects/XAI/causal/causal_discovery.py:124: RuntimeWarning: invalid value encountered in multiply\n",
      "  G_h = E.T * W * 2\n",
      "/Users/alextang/Documents/Dev/Py_Projects/XAI/causal/causal_discovery.py:136: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  obj = loss + 0.5 * rho * h * h + alpha * h + lambda1 * w.sum()\n",
      "/Users/alextang/Documents/Dev/Py_Projects/XAI/causal/causal_discovery.py:137: RuntimeWarning: invalid value encountered in multiply\n",
      "  G_smooth = G_loss + (rho * h + alpha) * G_h\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.           0.          -0.5920529    0.           0.\n",
      "    0.           0.           0.        ]\n",
      " [  0.16608836   0.         111.22887716   0.           0.\n",
      "    0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.           0.\n",
      "    0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.           0.\n",
      "    0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.           0.\n",
      "    0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.           0.\n",
      "    0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.           0.\n",
      "    0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.           0.\n",
      "    0.           0.           0.        ]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "execution_count": 141
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T23:20:52.707400Z",
     "start_time": "2025-09-14T23:20:52.674330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Estimand and Estimate of causality\n",
    "# import statsmodels.api as sm\n",
    "# from dowhy import CausalModel\n",
    "#\n",
    "# # Using the Gaussian Family for multi class\n",
    "# method_params_gaussian = {\n",
    "#     \"glm_family\": sm.families.Gaussian()\n",
    "# }\n",
    "#\n",
    "# # Using binomial for binary class\n",
    "# method_params_binomial = {\n",
    "#     \"glm_family\": sm.families.Binomial()\n",
    "# }\n",
    "#\n",
    "#\n",
    "# # Method\n",
    "# method_name = {\n",
    "#     'regression':'backdoor.generalized_linear_model',\n",
    "#     'distance_matching': 'backdoor.distance_matching',\n",
    "#     'propensity_score_stratification': 'backdoor.propensity_score_stratification',\n",
    "#     'propensity_score_matching': 'backdoor.propensity_score_matching',\n",
    "#     'frontdoor_regression': 'frontdoor.linear_regression'\n",
    "# }\n",
    "#\n",
    "# graph = utils.make_graph(adj_matrix_NOTEARS, labels=node_names)\n",
    "# print(graph)\n",
    "# print(type(graph))\n",
    "#\n",
    "# # Total effective\n",
    "# # causal_model, causal_estimand, causal_estimate = ide.estimate(\n",
    "# #     df,\n",
    "# #     treatment = 'acl',\n",
    "# #     outcome = 'class',\n",
    "# #     method_params = method_params_binomial,\n",
    "# #     method_name = 'backdoor.linear_regression',\n",
    "# #     graph = graph,\n",
    "# # )\n",
    "# # print(causal_model)\n",
    "# # print('*-'*50)\n",
    "# # print(causal_estimand)\n",
    "# # print('*-'*50)\n",
    "# # print(causal_estimate)\n",
    "# # print('*-'*50)\n",
    "#\n",
    "# graph_dot = utils.str_to_dot(graph.source)\n",
    "#\n",
    "# model=CausalModel(\n",
    "#             data = df,\n",
    "#             treatment='hed',\n",
    "#             outcome='class',\n",
    "#             graph=graph_dot\n",
    "# )\n",
    "#\n",
    "# # Identification\n",
    "# estimand = model.identify_effect(proceed_when_unidentifiable=False)\n",
    "# print(estimand)"
   ],
   "id": "b1e54c5dd4be42f7",
   "outputs": [],
   "execution_count": 142
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T23:20:52.764993Z",
     "start_time": "2025-09-14T23:20:52.743278Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Estimation\n",
    "# estimate = model.estimate_effect(\n",
    "#     estimand,\n",
    "#     method_params=method_params_binomial,\n",
    "#     method_name='backdoor.linear_regression',\n",
    "#     confidence_intervals=True,\n",
    "#     test_significance=True,\n",
    "#     target_units='ate'\n",
    "# )\n",
    "# print(estimate)"
   ],
   "id": "9e2d1e6392c628ee",
   "outputs": [],
   "execution_count": 143
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T23:20:52.814723Z",
     "start_time": "2025-09-14T23:20:52.784452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Natural direct effect (nde)\n",
    "# identified_estimand_nde = causal_model.identify_effect(estimand_type=\"nonparametric-nde\",\n",
    "#                                             proceed_when_unidentifiable=True)\n",
    "# print(identified_estimand_nde)\n",
    "#\n",
    "#\n",
    "# # Natural indirect effect (nie)\n",
    "# identified_estimand_nie = causal_model.identify_effect(estimand_type=\"nonparametric-nie\",\n",
    "#                                             proceed_when_unidentifiable=True)\n",
    "# print(identified_estimand_nie)\n",
    "#\n",
    "#\n",
    "# import dowhy.causal_estimators.linear_regression_estimator\n",
    "# causal_estimate_nie = causal_model.estimate_effect(identified_estimand_nie,\n",
    "#                                         method_name=\"mediation.two_stage_regression\",\n",
    "#                                        confidence_intervals=True,\n",
    "#                                        test_significance=True,\n",
    "#                                         method_params = {\n",
    "#                                             'first_stage_model': dowhy.causal_estimators.linear_regression_estimator.LinearRegressionEstimator,\n",
    "#                                             'second_stage_model': dowhy.causal_estimators.linear_regression_estimator.LinearRegressionEstimator\n",
    "#                                         }\n",
    "#                                        )\n",
    "# print(causal_estimate_nie)"
   ],
   "id": "9edabc322505f864",
   "outputs": [],
   "execution_count": 144
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T23:20:52.855918Z",
     "start_time": "2025-09-14T23:20:52.827899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Refute estimand\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"dowhy\")\n",
    "#\n",
    "#\n",
    "# refuter_list = ['bootstrap_refuter', \"data_subset_refuter\", 'dummy_outcome_refuter', 'placebo_treatment_refuter', 'random_common_cause']\n",
    "# # r1 = model.refute_estimate(estimand, estimate, method_name=\"bootstrap_refuter\")\n",
    "# # r2 = model.refute_estimate(estimand, estimate, method_name=\"data_subset_refuter\")\n",
    "# # r3 = model.refute_estimate(estimand, estimate, method_name=\"dummy_outcome_refuter\")\n",
    "# # r4 = model.refute_estimate(estimand, estimate, method_name=\"placebo_treatment_refuter\")\n",
    "# # r5 = model.refute_estimate(estimand, estimate, method_name=\"random_common_cause\")\n",
    "# for refuters in refuter_list:\n",
    "#     refute_results = ref.causal_refuter(model, estimand, estimate, method_name=refuters)\n",
    "#     print(refute_results)\n",
    "#     print('*'*100)"
   ],
   "id": "28bb440a37c45172",
   "outputs": [],
   "execution_count": 145
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T23:31:53.700889Z",
     "start_time": "2025-09-14T23:31:51.133501Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(df)\n",
    "filter_col = ['senderPseudo','pos', 'acl', 'spd', 'hed', 'class']\n",
    "# filter_col = ['acl', 'spd', 'class']\n",
    "# filter_col = ['sendTime', 'messageID', 'class']\n",
    "# filter_col = ['senderPseudo', 'class']\n",
    "# filter_col = ['senderPseudo', 'acl', 'spd', 'class']\n",
    "df_filtered = df.loc[:, filter_col].copy()\n",
    "print(df_filtered)\n",
    "\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    HAS_XGB = True\n",
    "except Exception:\n",
    "    HAS_XGB = False\n",
    "    print(\"No XGBoost available\")\n",
    "\n",
    "def evaluate_plain(df_like, name, models, n_splits=5):\n",
    "    if 'class' not in df_like.columns:\n",
    "        raise ValueError(f\"{name} No target col 'class'\")\n",
    "\n",
    "    data = df_like.dropna(subset=['class']).copy()\n",
    "    y = data['class'].astype(int).values\n",
    "    X = data.drop(columns=['class'])\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    rows = []\n",
    "    preds_dict = {}\n",
    "    for model_name, est in models.items():\n",
    "        y_pred = cross_val_predict(est, X, y, cv=cv, method='predict', n_jobs=-1)\n",
    "        preds_dict[model_name] = y_pred\n",
    "\n",
    "        acc = accuracy_score(y, y_pred)\n",
    "        rec = recall_score(y, y_pred, zero_division=0)\n",
    "        f1  = f1_score(y, y_pred, zero_division=0)\n",
    "\n",
    "        cm = confusion_matrix(y, y_pred)\n",
    "        print(f\"\\n[{name}] {model_name}\")\n",
    "        print(f\"Accuracy: {acc:.4f} | Recall: {rec:.4f} | F1: {f1:.4f}\")\n",
    "        print(\"Confusion Matrix [[TN, FP], [FN, TP]]:\")\n",
    "        print(cm)\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y, y_pred, digits=4, zero_division=0))\n",
    "\n",
    "        rows.append({\n",
    "            'FeatureSet': name,\n",
    "            'Model': model_name,\n",
    "            'Accuracy': acc,\n",
    "            'Recall': rec,\n",
    "            'F1': f1\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows).set_index(['FeatureSet','Model'])\n",
    "\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000, solver='lbfgs'),\n",
    "    'DecisionTree(max_depth=6)': DecisionTreeClassifier(max_depth=6, random_state=42),\n",
    "}\n",
    "if HAS_XGB:\n",
    "    models['XGBoost'] = XGBClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.08,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.9,\n",
    "        reg_lambda=1.0,\n",
    "        objective='binary:logistic',\n",
    "        eval_metric='logloss',\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "res_full = evaluate_plain(df, name='Full', models=models)\n",
    "res_flt  = evaluate_plain(df_filtered, name='Filtered', models=models)\n",
    "print(res_full)\n",
    "print(res_flt)\n",
    "\n",
    "# summary = pd.concat([res_full, res_flt]).reset_index()\n",
    "\n",
    "# print(\"\\n=== Summary Table ===\")\n",
    "# print(summary.pivot(index='Model', columns='FeatureSet', values=['Accuracy','Recall','F1']).round(4))\n"
   ],
   "id": "6ffb5b68ade0bf14",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           sendTime  senderPseudo  messageID       pos       spd       acl  \\\n",
      "28678   72524.93554     101314037  427449123  1.177110  1.905615  0.053295   \n",
      "200107  25997.45431      10126152   24069906  2.795565  0.062502  0.005667   \n",
      "430083  51456.19907      10747875  227970587  0.889361  1.033074  1.867734   \n",
      "672050  63495.90880      10977316  294191998  1.685966  1.864182  0.313507   \n",
      "598240  62513.11618      10942036  281163403  1.820064  2.141214  0.343610   \n",
      "...             ...           ...        ...       ...       ...       ...   \n",
      "867493  57363.97413      10824615  246269618  1.185938  1.932187  0.352998   \n",
      "611642  62679.81393      10948636  282448261  1.032245  1.947845  0.062069   \n",
      "255116  26914.40500      10152432   32398993  1.403602  0.342722  1.299022   \n",
      "907233  40395.11123      20524134  159076506  1.373236  0.062503  0.005626   \n",
      "807673  54925.09253      10797675  240617007  1.541126  1.599667  0.088822   \n",
      "\n",
      "             hed  class  \n",
      "28678   1.402316      0  \n",
      "200107  0.124483      1  \n",
      "430083  1.300563      0  \n",
      "672050  1.374822      1  \n",
      "598240  1.558776      0  \n",
      "...          ...    ...  \n",
      "867493  1.503008      0  \n",
      "611642  1.389474      0  \n",
      "255116  1.446657      0  \n",
      "907233  1.325739      1  \n",
      "807673  1.358574      0  \n",
      "\n",
      "[100000 rows x 8 columns]\n",
      "        senderPseudo       pos       acl       spd       hed  class\n",
      "28678      101314037  1.177110  0.053295  1.905615  1.402316      0\n",
      "200107      10126152  2.795565  0.005667  0.062502  0.124483      1\n",
      "430083      10747875  0.889361  1.867734  1.033074  1.300563      0\n",
      "672050      10977316  1.685966  0.313507  1.864182  1.374822      1\n",
      "598240      10942036  1.820064  0.343610  2.141214  1.558776      0\n",
      "...              ...       ...       ...       ...       ...    ...\n",
      "867493      10824615  1.185938  0.352998  1.932187  1.503008      0\n",
      "611642      10948636  1.032245  0.062069  1.947845  1.389474      0\n",
      "255116      10152432  1.403602  1.299022  0.342722  1.446657      0\n",
      "907233      20524134  1.373236  0.005626  0.062503  1.325739      1\n",
      "807673      10797675  1.541126  0.088822  1.599667  1.358574      0\n",
      "\n",
      "[100000 rows x 6 columns]\n",
      "\n",
      "[Full] LogisticRegression\n",
      "Accuracy: 0.8316 | Recall: 0.0979 | F1: 0.1784\n",
      "Confusion Matrix [[TN, FP], [FN, TP]]:\n",
      "[[81332     0]\n",
      " [16840  1828]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8285    1.0000    0.9062     81332\n",
      "           1     1.0000    0.0979    0.1784     18668\n",
      "\n",
      "    accuracy                         0.8316    100000\n",
      "   macro avg     0.9142    0.5490    0.5423    100000\n",
      "weighted avg     0.8605    0.8316    0.7703    100000\n",
      "\n",
      "\n",
      "[Full] DecisionTree(max_depth=6)\n",
      "Accuracy: 0.8987 | Recall: 0.4577 | F1: 0.6279\n",
      "Confusion Matrix [[TN, FP], [FN, TP]]:\n",
      "[[81327     5]\n",
      " [10123  8545]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8893    0.9999    0.9414     81332\n",
      "           1     0.9994    0.4577    0.6279     18668\n",
      "\n",
      "    accuracy                         0.8987    100000\n",
      "   macro avg     0.9444    0.7288    0.7846    100000\n",
      "weighted avg     0.9099    0.8987    0.8829    100000\n",
      "\n",
      "\n",
      "[Full] XGBoost\n",
      "Accuracy: 0.9037 | Recall: 0.4863 | F1: 0.6534\n",
      "Confusion Matrix [[TN, FP], [FN, TP]]:\n",
      "[[81290    42]\n",
      " [ 9590  9078]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8945    0.9995    0.9441     81332\n",
      "           1     0.9954    0.4863    0.6534     18668\n",
      "\n",
      "    accuracy                         0.9037    100000\n",
      "   macro avg     0.9449    0.7429    0.7987    100000\n",
      "weighted avg     0.9133    0.9037    0.8898    100000\n",
      "\n",
      "\n",
      "[Filtered] LogisticRegression\n",
      "Accuracy: 0.8169 | Recall: 0.0192 | F1: 0.0376\n",
      "Confusion Matrix [[TN, FP], [FN, TP]]:\n",
      "[[81332     0]\n",
      " [18310   358]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8162    1.0000    0.8988     81332\n",
      "           1     1.0000    0.0192    0.0376     18668\n",
      "\n",
      "    accuracy                         0.8169    100000\n",
      "   macro avg     0.9081    0.5096    0.4682    100000\n",
      "weighted avg     0.8505    0.8169    0.7381    100000\n",
      "\n",
      "\n",
      "[Filtered] DecisionTree(max_depth=6)\n",
      "Accuracy: 0.8987 | Recall: 0.4577 | F1: 0.6279\n",
      "Confusion Matrix [[TN, FP], [FN, TP]]:\n",
      "[[81327     5]\n",
      " [10123  8545]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8893    0.9999    0.9414     81332\n",
      "           1     0.9994    0.4577    0.6279     18668\n",
      "\n",
      "    accuracy                         0.8987    100000\n",
      "   macro avg     0.9444    0.7288    0.7846    100000\n",
      "weighted avg     0.9099    0.8987    0.8829    100000\n",
      "\n",
      "\n",
      "[Filtered] XGBoost\n",
      "Accuracy: 0.9017 | Recall: 0.4824 | F1: 0.6470\n",
      "Confusion Matrix [[TN, FP], [FN, TP]]:\n",
      "[[81168   164]\n",
      " [ 9662  9006]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8936    0.9980    0.9429     81332\n",
      "           1     0.9821    0.4824    0.6470     18668\n",
      "\n",
      "    accuracy                         0.9017    100000\n",
      "   macro avg     0.9379    0.7402    0.7950    100000\n",
      "weighted avg     0.9101    0.9017    0.8877    100000\n",
      "\n",
      "                                      Accuracy    Recall        F1\n",
      "FeatureSet Model                                                  \n",
      "Full       LogisticRegression          0.83160  0.097922  0.178376\n",
      "           DecisionTree(max_depth=6)   0.89872  0.457735  0.627893\n",
      "           XGBoost                     0.90368  0.486287  0.653376\n",
      "                                      Accuracy    Recall        F1\n",
      "FeatureSet Model                                                  \n",
      "Filtered   LogisticRegression          0.81690  0.019177  0.037633\n",
      "           DecisionTree(max_depth=6)   0.89872  0.457735  0.627893\n",
      "           XGBoost                     0.90174  0.482430  0.647029\n"
     ]
    }
   ],
   "execution_count": 151
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
